
INFO:root:Epoch 1
/home/brett/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Process Process-1:
Traceback (most recent call last):
  File "/home/brett/anaconda3/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/brett/anaconda3/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/brett/Desktop/tutorials/ijepa/ijepa/main_ijepa.py", line 54, in process_main
    app_main(args=params)
  File "/home/brett/Desktop/tutorials/ijepa/ijepa/src/train.py", line 452, in main
    (loss, _new_lr, _new_wd, grad_stats), etime = gpu_timer(train_step)
  File "/home/brett/Desktop/tutorials/ijepa/ijepa/src/utils/logging.py", line 21, in gpu_timer
    result = closure()
  File "/home/brett/Desktop/tutorials/ijepa/ijepa/src/train.py", line 431, in train_step
    z = forward_context()
  File "/home/brett/Desktop/tutorials/ijepa/ijepa/src/train.py", line 420, in forward_context
    z = predictor(z, masks_enc, masks_pred)
  File "/home/brett/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/brett/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/brett/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/brett/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/brett/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/brett/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/brett/Desktop/tutorials/ijepa/ijepa/src/models/vision_transformer.py", line 319, in forward
    x = blk(x)
  File "/home/brett/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/brett/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/brett/Desktop/tutorials/ijepa/ijepa/src/models/vision_transformer.py", line 166, in forward
    y, attn = self.attn(self.norm1(x))
  File "/home/brett/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/brett/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/brett/Desktop/tutorials/ijepa/ijepa/src/models/vision_transformer.py", line 143, in forward
    attn = (q @ k.transpose(-2, -1)) * self.scale
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 84.00 MiB. GPU 0 has a total capacity of 10.90 GiB of which 23.94 MiB is free. Including non-PyTorch memory, this process has 10.85 GiB memory in use. Of the allocated memory 10.48 GiB is allocated by PyTorch, and 92.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)